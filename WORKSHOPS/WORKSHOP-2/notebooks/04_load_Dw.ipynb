{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e93c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a553a4b",
   "metadata": {},
   "source": [
    "# 1) Parametros de conexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ae5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "usuario = \"etluser\"\n",
    "password = \"etlpass\"\n",
    "host = \"localhost\"\n",
    "puerto = \"5432\"\n",
    "base_datos = \"dw\"\n",
    "\n",
    "engine = create_engine(f\"postgresql://{usuario}:{password}@{host}:{puerto}/{base_datos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeffc986",
   "metadata": {},
   "source": [
    "# 2) Crear tablas ejecutando el schema.sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd44a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema creado correctamente en PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "with open(\"..//dw/schema.sql\", \"r\", encoding=\"utf-8\") as f:\n",
    "    schema_sql = f.read()\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(schema_sql))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"Esquema creado correctamente en PostgreSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fdf833",
   "metadata": {},
   "source": [
    "# 3) Leer datos curated (used_cars_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59220264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado desde tabla curated (300 filas)\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM Used_cars_final;\"\n",
    "df = pd.read_sql(query, engine)\n",
    "print(f\"Dataset cargado desde tabla curated ({len(df)} filas)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145aa2f",
   "metadata": {},
   "source": [
    "# 4) Cargamos dimensiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "940e9c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_brand poblada\n",
      "dim_model poblada\n",
      "dim_location poblada\n",
      "dim_date poblada\n"
     ]
    }
   ],
   "source": [
    "# ---- dim_brand ----\n",
    "dim_brand = df[['brand', 'country']].drop_duplicates().rename(\n",
    "    columns={'brand': 'brand_name', 'country': 'brand_country'}\n",
    ")\n",
    "dim_brand.to_sql('dim_brand', engine, if_exists='append', index=False)\n",
    "print(\"dim_brand poblada\")\n",
    "\n",
    "# ---- dim_model ----\n",
    "brand_ids = pd.read_sql(\"SELECT brand_id, brand_name FROM dim_brand;\", engine)\n",
    "dim_model = (\n",
    "    df[['brand', 'model']]\n",
    "    .drop_duplicates()\n",
    "    .merge(brand_ids, left_on='brand', right_on='brand_name')\n",
    "    [['brand_id', 'model']]\n",
    "    .rename(columns={'model': 'model_name'})\n",
    ")\n",
    "dim_model.to_sql('dim_model', engine, if_exists='append', index=False)\n",
    "print(\"dim_model poblada\")\n",
    "\n",
    "# ---- dim_location ----\n",
    "dim_location = df[['city', 'state', 'country']].drop_duplicates()\n",
    "dim_location.to_sql('dim_location', engine, if_exists='append', index=False)\n",
    "print(\"dim_location poblada\")\n",
    "\n",
    "# ---- dim_date ----\n",
    "dim_date = pd.DataFrame({\n",
    "    'full_date': pd.to_datetime(df['listing_date'])\n",
    "}).drop_duplicates().sort_values('full_date')\n",
    "\n",
    "dim_date['date_id'] = range(1, len(dim_date) + 1)\n",
    "dim_date['year'] = dim_date['full_date'].dt.year\n",
    "dim_date['quarter'] = dim_date['full_date'].dt.quarter\n",
    "dim_date['month'] = dim_date['full_date'].dt.month\n",
    "dim_date['day'] = dim_date['full_date'].dt.day\n",
    "dim_date['day_name'] = dim_date['full_date'].dt.day_name()\n",
    "dim_date['weekofyear'] = dim_date['full_date'].dt.isocalendar().week\n",
    "\n",
    "dim_date.to_sql('dim_date', engine, if_exists='append', index=False)\n",
    "print(\"dim_date poblada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a40b5",
   "metadata": {},
   "source": [
    "# 5) Poblar tabla de hecho fact_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06dc3911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_listings poblada correctamente\n",
      "\n",
      "Carga completa del Data Warehouse finalizada con éxito\n"
     ]
    }
   ],
   "source": [
    "# Cargar IDs de dimensiones\n",
    "brand_ids = pd.read_sql(\"SELECT * FROM dim_brand;\", engine)\n",
    "model_ids = pd.read_sql(\"SELECT * FROM dim_model;\", engine)\n",
    "location_ids = pd.read_sql(\"SELECT * FROM dim_location;\", engine)\n",
    "date_ids = pd.read_sql(\"SELECT * FROM dim_date;\", engine)\n",
    "\n",
    "# Unir dataset principal con las dimensiones\n",
    "fact_df = (\n",
    "    df.merge(brand_ids, left_on='brand', right_on='brand_name', how='left')\n",
    "      .merge(model_ids, left_on=['model', 'brand_id'], right_on=['model_name', 'brand_id'], how='left')\n",
    "      .merge(location_ids, on=['city', 'state', 'country'], how='left')\n",
    "      .merge(date_ids, left_on='listing_date', right_on='full_date', how='left')\n",
    ")\n",
    "\n",
    "# Limpieza y preparación\n",
    "fact_df = fact_df.rename(columns={'key': 'listing_key'})\n",
    "\n",
    "# Verificamos si year se renombró en los merges\n",
    "if 'year_x' in fact_df.columns:\n",
    "    fact_df = fact_df.rename(columns={'year_x': 'year'})\n",
    "elif 'year_y' in fact_df.columns:\n",
    "    fact_df = fact_df.rename(columns={'year_y': 'year'})\n",
    "\n",
    "# Seleccionamos solo las columnas necesarias\n",
    "cols_utiles = [\n",
    "    'listing_id',\n",
    "    'listing_key',\n",
    "    'model_id',\n",
    "    'location_id',\n",
    "    'seller_type',\n",
    "    'fuel',\n",
    "    'transmission',\n",
    "    'year',\n",
    "    'mileage_km',\n",
    "    'price_usd',\n",
    "    'price_clean',\n",
    "    'currency',\n",
    "    'date_id'\n",
    "]\n",
    "\n",
    "fact_df = fact_df[[c for c in cols_utiles if c in fact_df.columns]]\n",
    "\n",
    "# Renombrar para coincidir con la tabla de hechos\n",
    "fact_df = fact_df.rename(columns={\n",
    "    'listing_id': 'listing_natural_id',\n",
    "    'listing_key': 'listing_key',\n",
    "    'date_id': 'listing_date_id'\n",
    "})\n",
    "\n",
    "# Insertar en la tabla de hechos\n",
    "fact_df.to_sql('fact_listings', engine, if_exists='append', index=False)\n",
    "print(\"act_listings poblada correctamente\")\n",
    "\n",
    "print(\"\\nCarga completa del Data Warehouse finalizada con éxito\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
